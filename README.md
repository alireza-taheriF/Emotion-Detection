# ğŸ­ Real-Time Emotion Detection from Facial Expressions

A deep learningâ€“based emotion recognition system trained on the FER-2013 dataset and tested on real-time webcam input using PyTorch and OpenCV.

---

## ğŸ“‚ Project Structure

```markdown
emotion_detector/
â”œâ”€â”€ assets/
â”‚ â”œâ”€â”€ emotion_log.csv
â”‚ â””â”€â”€ confusion_matrix.png
â”œâ”€â”€ data/
â”‚ â””â”€â”€ fer2013/
â”‚ â”œâ”€â”€ train.csv
â”‚ â””â”€â”€ test.csv
â”œâ”€â”€ models/
â”‚ â””â”€â”€ custom_emotion_cnn.pth
â”œâ”€â”€ src/
â”‚ â”œâ”€â”€ main.py
â”‚ â”œâ”€â”€ model.py
â”‚ â”œâ”€â”€ train_model.py
â”‚ â”œâ”€â”€ camera_emotion_custom.py
â”‚ â”œâ”€â”€ emotion_utils.py
â”‚ â”œâ”€â”€ evaluate_model.py
â”‚ â””â”€â”€ analyze_emotions.py
â”œâ”€â”€ FERPlus/ (optional)
â”‚ â”œâ”€â”€ src/
â”‚ â””â”€â”€ data/
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```

> âš ï¸ Due to GitHub file size limits, some large files like `train.csv`, `test.csv`, and the trained model `custom_emotion_cnn.pth` are not included. Instructions for obtaining them are provided below.

---

## ğŸ§  Model Info

- **Architecture**: Custom CNN (built from scratch)
- **Dataset**: [FER-2013](https://www.kaggle.com/datasets/msambare/fer2013)
- **Framework**: PyTorch
- **Test Accuracy**: ~61%

---

## ğŸ“Š Evaluation Metrics

| Emotion  | Precision | Recall | F1-score | Support |
|----------|-----------|--------|----------|---------|
| Angry    | 0.46      | 0.54   | 0.50     | 467     |
| Disgust  | 0.68      | 0.48   | 0.56     | 56      |
| Fear     | 0.53      | 0.41   | 0.46     | 496     |
| Happy    | 0.80      | 0.80   | 0.80     | 895     |
| Sad      | 0.55      | 0.45   | 0.49     | 653     |
| Surprise | 0.79      | 0.76   | 0.77     | 415     |
| Neutral  | 0.47      | 0.60   | 0.53     | 607     |

- **Overall Accuracy**: 61% (on 3589 test samples)

---

## ğŸ¥ Run Real-Time Emotion Detection

Make sure your webcam is connected, and then run:

```bash
python src/camera_emotion_custom.py
```
Predictions will appear live on your face in the webcam feed.

## âš™ï¸ Setup Instructions
1. Clone the repository
```bash
git clone https://github.com/alireza-taheriF/Emotion-Detection.git
cd Emotion-Detection
```

2. Create a virtual environment
```bash
python -m venv venv
source venv/bin/activate  # Windows: venv\Scripts\activate
```

3. Install dependencies
```bash
pip install -r requirements.txt
```

. Download FER-2013 dataset: https://www.kaggle.com/datasets/msambare/fer2013
â†’ Place train.csv and test.csv inside data/fer2013/
. Either:
. Train the model using src/train_model.py
. Or use the pre-trained model by requesting custom_emotion_cnn.pth from the author

## ğŸªª License
MIT License
Author: Alireza Taheri Fakhr
Purpose: Research experience and resume-building for a future multi-modal (audio-visual) emotion detection system

## ğŸ“« Contact
Feel free to connect:
ğŸ“§ alirezataherifakhr@gmail.com
ğŸ’¼ LinkedIn: https://www.linkedin.com/in/alireza-taheri-a34179164/


